{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a7bcf3",
   "metadata": {},
   "source": [
    "<h3>Preprocess the Audio</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca837b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2025-06-17-git-ee1f79b0fa-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with gcc 15.1.0 (Rev4, Built by MSYS2 project)\n",
      "configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-openal --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "libavutil      60.  3.100 / 60.  3.100\n",
      "libavcodec     62.  3.101 / 62.  3.101\n",
      "libavformat    62.  1.100 / 62.  1.100\n",
      "libavdevice    62.  0.100 / 62.  0.100\n",
      "libavfilter    11.  0.100 / 11.  0.100\n",
      "libswscale      9.  0.100 /  9.  0.100\n",
      "libswresample   6.  0.100 /  6.  0.100\n",
      "\n",
      "Exiting with exit code 0\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e59285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:/Users/HP/Desktop/fyp/data/raw_audio\"\n",
    "output_path = r\"C:/Users/HP/Desktop/fyp/data/processed_audio\"\n",
    "\n",
    "#create the output path folder\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93bfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):\n",
    "        #load audio file using pydub\n",
    "        audio = AudioSegment.from_file(os.path.join(input_path, filename))\n",
    "        #convert the audio file to 16kHx and mono-use one channel onlu to reduce model complexity\n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "        #change the ext from mp3 to wav\n",
    "        new_name = filename.replace(\".mp3\", \".wav\")\n",
    "        #export audio to the output path\n",
    "        audio.export(os.path.join(output_path, new_name), format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e76309",
   "metadata": {},
   "source": [
    "This process is important because Fatser-Whisper expects audios in `.wav` fomat, mono and `16kHz`. If this stepp is skipped we'll get errors when trainin or transcribing as we will be using this audio files to fine tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd43685",
   "metadata": {},
   "source": [
    "<h3>Create the Transcipt file</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b7498",
   "metadata": {},
   "source": [
    "Creation of the transcript file will be done manually via excel to dave time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Id\" : [i for i in range(len(os.listdir(output_path)))],\n",
    "    \"Audio_Filename\" : [filename for filename in os.listdir(output_path)],\n",
    "    \"Text\": [row for row in pd.read_csv(r\"C:/Users/HP\\Desktop/fyp/data/audio_text_mapping.csv\")[\"Text\"]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e355ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Audio_Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>audio_sample_1.wav</td>\n",
       "      <td>Its images were used by among others Palestini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>audio_sample_10.wav</td>\n",
       "      <td>The Argand lamp used whale oil, olive oil and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>audio_sample_100.wav</td>\n",
       "      <td>Alice was default reading to the point where I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>audio_sample_1000.wav</td>\n",
       "      <td>The Sankwala mountain ranges were first explor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>audio_sample_1001.wav</td>\n",
       "      <td>A slough is a wetland usually a swamp or shall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id         Audio_Filename  \\\n",
       "0   0     audio_sample_1.wav   \n",
       "1   1    audio_sample_10.wav   \n",
       "2   2   audio_sample_100.wav   \n",
       "3   3  audio_sample_1000.wav   \n",
       "4   4  audio_sample_1001.wav   \n",
       "\n",
       "                                                Text  \n",
       "0  Its images were used by among others Palestini...  \n",
       "1  The Argand lamp used whale oil, olive oil and ...  \n",
       "2  Alice was default reading to the point where I...  \n",
       "3  The Sankwala mountain ranges were first explor...  \n",
       "4  A slough is a wetland usually a swamp or shall...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert data into a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb822b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tsv, standard format for Whisper\n",
    "df.to_csv(\"data.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce928a",
   "metadata": {},
   "source": [
    "<h3>Split into Train, test and Eval Sets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c15f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load the data\n",
    "df = pd.read_csv(\"data.tsv\", sep=\"\\t\")\n",
    "\n",
    "#split into train and temp\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=40)\n",
    "\n",
    "#split temp into eval and test sets\n",
    "eval, test = train_test_split(temp, test_size=0.5, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95329aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to tsv file\n",
    "train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "eval.to_csv(\"eval.tsv\", sep=\"\\t\", index=False)\n",
    "test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140935e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
